### Recap

*Il processore si evolve durante le operazioni di :* 
- *fetch*
- *decode*
- *execute*

Prelevando i dati dalla RAM nell'area text, dopo di che c'è l'area con i dati globali e in fine lo heap e lo stack e ciò può essere interrotto da un segnale elettrico chiamato l'interrupt.

Si ha anche un'interrupt collegato al clock del sistema hardware che, molto frequentemente, interrompe il processore ed attiva lo **scheduler** per controllare e far eseguire le altre operazioni del sistema operativo.

**Scheduler** è un processo che viene innescato interrompendo il sistema per eseguire le altre operazioni che sono menzionati sopra.

**Contesto** - insieme di registri, variabili di ambiente, puntatore di stack, program counter e le altre variabili che vengono salvate per riavviare il programma che viene fermato, per le altre attività dello scheduler, in modo da avere il programma allo stesso punto di quando era stato fermato.

**Quando si hanno più core**, si può parallelizzare anche lo scheduler ma è troppo complicato. Quindi lo scheduler ha più operazioni da fare e **diventa tutto molto più complicato.** E' quindi meglio lasciare lo scheduler riavviare il processo interrotto sullo stesso processore da cui viene interrotto perché è più probabile che quel processore abbia ancora i dati nella cache, permettendo di riavviare il processo parzialmente, questa è chiamata **processor affinity**. *(Affinità - numero del core dove il processo gira, non è fissa e viene aggiornata dallo scheduler)*

*Se non si trovano più i dati nella cache perché lo scheduler  ha deciso di riavviare il processo su un altro core, i dati vengono presi dalla RAM.*

*Realtime clock - chip che innesca questi interrupt, non è il clock del processore.*

Tipicamente lo il campanello dello scheduler suona molto più frequentemente, solitamente 1000 al millisecondo, così riesce a leggere la lista e vedere a quali core e processori tocca, quali processori girano e quali sono fermi.

Tempo medio di un processo prima che venga interrotto è di 10-20-30 millisecondi e viene definito dal time-slice : algoritmi che fanno in modo da non far vedere all'utente che sta avvenendo, dando priorità alle attività di kernel.

Su un server invece i tempi sono più larghi, lasciando più tempo al processore e al processo perché non c'è un utente tutto il tempo.
### Concorrenza tra processi

**Thread** - percorso di esecuzione all'interno di un processore.
**Processo** - programma caricato in memoria, che utilizza le risorse del processore: RAM e periferiche. Quando caricato in memoria fa fetch decode execute, può essere mono-thread o creare dei thread dentro lo stesso processo. Se si usa il fork si crea invece un altro processo completamente indipendente.

Spooler di stampa - programma che manda i comandi alla stampa "tot" alla volta, visto che la stampante ha una memoria propria che fa abbastanza cagare. 

**Race condition** - quando 2 o più thread accedono alle stesse risorse senza alcuna protezione sovrascrivendosi a vicenda.
Per risolvere questa cosa si può usare MUTEX **(MUTual EXclusion lock)** primitiva (una funzione che esiste già) di sistema operativo per la sincronizzazione.
Per usarlo bisogna usare una variabile di  tipo `pthread_mutex_t mutex;` e a capo `pthread_mutex_init (&mutex, NULL);` oppure 
`pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;`  ed essenzialmente blocca gli altri thread all''esecuzione per far finire quello che è già in esecuzione.

![[Screenshot 2024-01-18 123040.png]]

problema = 

![[Screenshot 2024-01-18 123147.png]]

### Deadlock

Occorre evitare situazioni di deadlock distribuito, ovvero un intreccio delle
condizioni di attesa che rende impossibile il proseguire del flusso di esecuzione
di due o più thread, bloccandoli perennemente.
### Semaforo

E' un contatore che se è maggiore di 0 fa passare avanti facendo -1 per ogni operazione che passa e se è 0 non fa più passare nessuno.
